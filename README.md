# Threshold-DPO

A novel DPO framework that incorporates the strength of preferences in preference optimization. The framework is tested on state-of-the-art diffusion models and LLMs. All experiments in the paper can be replicated using this code.

The code includes experiments for diffusion models and Language models.

# Diffusion model experiments

Run shell scripts from launchers folder. Set relevant parameters in the file sd15.sh. To run diffusion model experiments first install requirements from requirements.txt. Diffusion models experiments part of this repo is forked from Diffusion-DPO repo. 

# Language model experiments 

The folder language_model is forked from odpo repo. Run language_model/run_all_experiments.sh. To run language model experiments, setup a virtual environment as directed in the original odpo repo.
